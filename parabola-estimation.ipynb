{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A: Supervised Machine Learning Algorithms\n",
    "## Homework Assignment 4\n",
    "## Question 6: Parabola Estimation Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** This Jupyter notebook contains starter codes for the Hyper-plane Estimation question. Use this notebook as a starting point to code the answers to this question. The skeleton of the functions you need to use is provided, you just need to fill the code where you are instructed to. Then generate a PDF file of the notebook and combine it with the other PDF files of your solution to the homework and submit a **single PDF file** to Gradescope.\n",
    "\n",
    "You will be instructed through a comment in each of the cells below whether you need to just run that cell or add code to it to complete the steps needed to solve the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:23.784744Z",
     "start_time": "2020-01-21T01:40:23.572772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Important packages (nothing to add to this cell)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:23.810363Z",
     "start_time": "2020-01-21T01:40:23.790089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the data (nothing to add to this cell)\n",
    "\n",
    "X_and_Y = np.load('./parabola-estimation.npy')\n",
    "old_X = X_and_Y[:, 0]  # Shape: (300,)\n",
    "Y = X_and_Y[:, 1]  # Shape: (300,)\n",
    "old_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:24.058373Z",
     "start_time": "2020-01-21T01:40:23.813997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization of the original datapoints (nothing to add to this cell).\n",
    "\n",
    "def vis(w0, w1, w2):\n",
    "    draw_plane = (w0 is not None) and (w1 is not None) and (w2 is not None)\n",
    "    if draw_plane:\n",
    "        X_line = np.linspace(0,10,300)\n",
    "        Y_line = w0 + w1 * X_line + w2 * (X_line**2)\n",
    "        plt.plot(X_line, Y_line, color='orange')\n",
    "        \n",
    "    plt.scatter(old_X, Y, color='gray')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()\n",
    "    \n",
    "vis(None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parabola Estimation with Squared $L_2$ Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume data points are represented as matrices $X$ and $Y$, please use the closed form solution to calculate the parameters $W$.\n",
    "\n",
    "**Hint**: You may refer to HW3 Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:24.065128Z",
     "start_time": "2020-01-21T01:40:24.059751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimating W, which defines the parabola estimation (you need to add code to this cell as indicated below).\n",
    "# y = w0 + w1*x + w2*x^2\n",
    "\n",
    "X = np.matrix(np.hstack((np.ones((len(old_X),1)),\n",
    "                         old_X.reshape(-1,1), \n",
    "                         (old_X**2).reshape(-1,1))))\n",
    "\n",
    "W = ####### Write your code here #######  Hint: In the form of X and Y.\n",
    "\n",
    "w0, w1, w2 = np.array(W).reshape(-1)\n",
    "print('y = {:.2f} + {:.2f}*x + {:.2f}*x^2'.format(w0, w1, w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:24.207227Z",
     "start_time": "2020-01-21T01:40:24.066372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization of the original datapoints and estimated plane (nothing to add to this cell).\n",
    "\n",
    "vis(w0, w1, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parabola Estimation with $L_1$  Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we would like to use the gradient descent to calculate the parameters $W$ for the parabola.\n",
    "If we have a loss function $\\mathcal{L}(W)$, then a typical gradient descent algorithm contains the following steps:\n",
    "\n",
    "**Step 1**. Initialize the parameters W.\n",
    "\n",
    "for i = 1 to #iterations:\n",
    "\n",
    "- **Step 2**. Compute the gradient $\\nabla \\mathcal{L}(W) = \\frac{\\partial \\mathcal{L}(W)}{\\partial W}$.\n",
    "\n",
    "- **Step 3**. Update the parameters $W \\leftarrow \\mathcal{L}(W) = W - \\eta \\frac{\\partial \\mathcal{L}(W)}{\\partial W}$ where $\\eta$ is the learning rate.\n",
    "\n",
    "**Hint**: You may refer to HW3 Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:24.210910Z",
     "start_time": "2020-01-21T01:40:24.208539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of L(W) with respect to W (you need to add code to this cell as indicated below).\n",
    "\n",
    "def grad_L_W(X, Y, W):\n",
    "    return ####### Write your code here ####### Hint: implement Step 2 above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:29.497555Z",
     "start_time": "2020-01-21T01:40:24.212089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimating W, which defines the hyperplane using gradient descent (you need to add code to this cell as indicated below).\n",
    "# y = w0 + w1*x + w2*x^2\n",
    "\n",
    "# Some settings.\n",
    "Y = Y.reshape(-1, 1)\n",
    "iterations    = 300000\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# Gradient descent algorithm.\n",
    "# Step 1. Initialize the parameters W.\n",
    "W = ####### To be filled. #######\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Step 2. Calculate the gradient of L(W) w.r.t. W. \n",
    "    grad = grad_L_W(X, Y, W)\n",
    "    \n",
    "    # Step 3. Update parameters W.\n",
    "    W = ####### Write your code here #######  Hint: Use grad, W, learning_rate to implement Step 3 above.\n",
    "\n",
    "# Print the parameters of the parabola.\n",
    "w0, w1, w2 = np.array(W).reshape(-1)\n",
    "print('y = {:.2f} + {:.2f}*x + {:.2f}*x^2'.format(w0, w1, w2))\n",
    "\n",
    "# Visualization.\n",
    "vis(w0, w1, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parabola Estimation with Squared $L_2$ Norm and $L_1$ Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we would like to use the gradient descent to calculate the parameters $W$ for the parabola.\n",
    "The loss function $\\mathcal{L}(W)$ now contains two parts: A squared $L_2$ norm and a $L_1$ norm.\n",
    "A coefficient $\\alpha$ is used to control the ratio of these two norms:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(W) \n",
    "& = \\sum_{i=1}^{n} \n",
    "\\Big(\\alpha\\big(\\mathbf{x}_i^T W - y_i\\big)^2 + (1-\\alpha)|\\mathbf{x}_i^T W - y_i| \\Big) \\\\\n",
    "& = \\alpha\\left\\lVert X W - Y \\right\\rVert_2^2 + (1-\\alpha)\\left\\lVert X W - Y \\right\\rVert_1 \\\\\n",
    "\\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Note:** It may take 2~3 mins to run the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:29.501485Z",
     "start_time": "2020-01-21T01:40:29.498811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of L(W) with respect to W (you need to add code to this cell as indicated below).\n",
    "\n",
    "def grad_L_W(X, Y, W, alpha):\n",
    "    \n",
    "    return ####### Write your code here #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:40:29.529671Z",
     "start_time": "2020-01-21T01:40:29.502593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to use gradient descent to estimate parabola given a list of alphas\n",
    "# (you need to add code to this cell as indicated below).\n",
    "# Hint: For each alpha, you need to use gradient descent, hence, you need to write a loop inside the loop.\n",
    "\n",
    "def parabola(alpha_list):\n",
    "    # Some settings.\n",
    "    global Y\n",
    "    plt.scatter(old_X, Y, color='gray')\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    iterations    = 300000\n",
    "    learning_rate = 0.000001\n",
    "    \n",
    "    # Loop over alpha(s).\n",
    "    for alpha in alpha_list:\n",
    "        \n",
    "        # Gradient descent algorithm.\n",
    "        # Step 1. Initialize the parameters W.\n",
    "        ####### Write your code here #######\n",
    "        \n",
    "        ####### To be filled. #######\n",
    "            # Step 2. Calculate the gradient of L(W) w.r.t. W. \n",
    "            ####### Write your code here #######\n",
    "            \n",
    "            # Step 3. Update parameters W.\n",
    "            ####### Write your code here #######\n",
    "\n",
    "        # Print the parameters of the parabola.\n",
    "        w0, w1, w2 = np.array(W).reshape(-1)\n",
    "        print('When alpha = {},'.format(alpha))\n",
    "        print('y = {:.2f} + {:.2f}*x + {:.2f}*x^2'.format(w0, w1, w2))\n",
    "\n",
    "        # Visualization.\n",
    "        X_line = np.linspace(0,10,300)\n",
    "        Y_line = w0 + w1 * X_line + w2 * (X_line**2)\n",
    "        plt.plot(X_line, Y_line, label='alpha={}'.format(alpha))\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:41:30.546466Z",
     "start_time": "2020-01-21T01:40:29.530798Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Estimate the parabolas given the list of alpha(s).\n",
    "parabola(alpha_list=[0,0.03,0.05,0.1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
